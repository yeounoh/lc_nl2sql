## 4\.1\.  Case Study: Upgrading Fossil to the NGQP


The [Fossil DVCS](http://www.fossil-scm.org/) is the version
control system used to track all of the SQLite source code.
A Fossil repository is an SQLite database file.
(Readers are invited to ponder this recursion as an independent exercise.)
Fossil is both the version\-control system for SQLite and a test
platform for SQLite. Whenever enhancements are made to SQLite,
Fossil is one of the first applications to test and evaluate those
enhancements. So Fossil was an early adopter of the NGQP.


Unfortunately, the NGQP caused a
performance regression in Fossil.


One of the many reports that Fossil makes available is a timeline of
changes to a single branch showing all merges in and out of that branch. See
[https://www.sqlite.org/src/timeline?nd\&n\=200\&r\=trunk](https://www.sqlite.org/src/timeline?nd&n=200&r=trunk)
for a typical
example of such a report. Generating such a report normally takes just
a few milliseconds. But after upgrading to the NGQP we noticed that
this one report was taking closer to 10 seconds for the trunk of the
repository.


The core query used to generate the branch timeline is shown below.
(Readers are not expected to understand the details of this query.
Commentary will follow.)



> ```
> 
> SELECT
>      blob.rid AS blobRid,
>      uuid AS uuid,
>      datetime(event.mtime,'localtime') AS timestamp,
>      coalesce(ecomment, comment) AS comment,
>      coalesce(euser, user) AS user,
>      blob.rid IN leaf AS leaf,
>      bgcolor AS bgColor,
>      event.type AS eventType,
>      (SELECT group_concat(substr(tagname,5), ', ')
>         FROM tag, tagxref
>        WHERE tagname GLOB 'sym-*'
>          AND tag.tagid=tagxref.tagid
>          AND tagxref.rid=blob.rid
>          AND tagxref.tagtype>0) AS tags,
>      tagid AS tagid,
>      brief AS brief,
>      event.mtime AS mtime
>   FROM event CROSS JOIN blob
>  WHERE blob.rid=event.objid
>    AND (EXISTS(SELECT 1 FROM tagxref
>                 WHERE tagid=11 AND tagtype>0 AND rid=blob.rid)
>         OR EXISTS(SELECT 1 FROM plink JOIN tagxref ON rid=cid
>                    WHERE tagid=11 AND tagtype>0 AND pid=blob.rid)
>         OR EXISTS(SELECT 1 FROM plink JOIN tagxref ON rid=pid
>                    WHERE tagid=11 AND tagtype>0 AND cid=blob.rid))
>  ORDER BY event.mtime DESC
>  LIMIT 200;
> 
> ```


This query is not
especially complicated, but even so it replaces hundreds or
perhaps thousands of lines of procedural code.
The gist of the query is this: Scan down the EVENT table looking
for the most recent 200 check\-ins that satisfy any one of three conditions:



1. The check\-in has a "trunk" tag.
2. The check\-in has a child that has a "trunk" tag.
3. The check\-in has a parent that has a "trunk" tag.



The first condition causes all of the trunk check\-ins to be displayed and
the second and third cause check\-ins that merge into or fork from
the trunk to also be included.
The three conditions are implemented by the three OR\-connected
EXISTS statements in the WHERE clause of the query.
The slowdown that occurred with the NGQP was caused by the second and
third conditions. The problem is the same in each, so we will examine
just the second one.
The subquery of the second condition can be rewritten (with minor
and immaterial simplifications) as follows:



> ```
> 
> SELECT 1
>   FROM plink JOIN tagxref ON tagxref.rid=plink.cid
>  WHERE tagxref.tagid=$trunk
>    AND plink.pid=$ckid;
> 
> ```


The PLINK table holds parent\-child relationships between
check\-ins. The TAGXREF table maps tags into check\-ins.
For reference, the relevant portions of the schemas
for these two tables is shown here:



> ```
> 
> CREATE TABLE plink(
>   pid INTEGER REFERENCES blob,
>   cid INTEGER REFERENCES blob
> );
> CREATE UNIQUE INDEX plink_i1 ON plink(pid,cid);
> 
> CREATE TABLE tagxref(
>   tagid INTEGER REFERENCES tag,
>   mtime TIMESTAMP,
>   rid INTEGER REFERENCE blob,
>   UNIQUE(rid, tagid)
> );
> CREATE INDEX tagxref_i1 ON tagxref(tagid, mtime);
> 
> ```


There are only two reasonable ways to implement this query.
(There are many other possible algorithms, but none of the
others are contenders for being the "best" algorithm.)


1. Find all children of check\-in $ckid and test each one to see if
it has the $trunk tag.
2. Find all check\-ins with the $trunk tag and test each one to see if
it is a child of $ckid.



Intuitively, we humans understand that algorithm\-1 is best.
Each check\-in is likely to have few children (one child is
the most common case) and each child can be tested for the
$trunk tag in logarithmic time. Indeed, algorithm\-1 is the
faster choice in practice. But the NGQP has no intuition. The
NGQP must use hard math, and algorithm\-2 is slightly
better mathematically. This is because, in the absence of other information,
the NGQP must assume that the indexes PLINK\_I1 and TAGXREF\_I1 are of
equal quality and are equally selective. Algorithm\-2 uses one field
of the TAGXREF\_I1 index and both fields of the PLINK\_I1 index whereas
algorithm\-1 only uses the first field of each index. Since
algorithm\-2 uses more index material, the NGQP is correct
to judge it to be the better algorithm. The scores are close and
algorithm\-2 just barely squeaks ahead of algorithm\-1\. But
algorithm\-2 really is the correct choice here.




Unfortunately, algorithm\-2 is slower than algorithm\-1 in
this application.




The problem is that the indexes are not of equal quality.
A check\-in is likely to only have one child. So the first
field of PLINK\_I1 will usually narrow down the search to just a single
row. But there are thousands and thousands check\-ins tagged with "trunk",
so the first field of TAGXREF\_I1 will be
of little help in narrowing down the search.




The NGQP has no way of knowing that TAGXREF\_I1 is almost useless in this
query, unless [ANALYZE](lang_analyze.html) has been run on the database. The [ANALYZE](lang_analyze.html) command
gathers statistics on the quality of the various indexes and stores those
statistics in [SQLITE\_STAT1](fileformat2.html#stat1tab) table.
Having access to this statistical information,
the NGQP easily chooses algorithm\-1 as the best algorithm, by a wide
margin.


Why didn't the legacy query planner choose algorithm\-2?
Easy: because the NN algorithm
never even considered algorithm\-2\. Graphs of the planning
problem look like this:





P

T


4\.8


4\.4

\*


 4\.9

\*


 5\.2
without ANALYZE

P

T


4\.4


3\.8

\*


 3\.9

\*


 6\.1
with ANALYZE




In the "without ANALYZE" case on the left, the NN algorithm chooses
loop P (PLINK) as the outer loop because 4\.9 is less than 5\.2, resulting
in path P\-T which is algorithm\-1\. NN only looks at the single best choice
at each step so it completely misses the fact that
5\.2\+4\.4 makes a slightly cheaper plan than 4\.9\+4\.8\. But the N3 algorithm
keeps track of the 5 best paths for a 2\-way join, so it ends up
selecting path T\-P because of its slightly lower overall cost.
Path T\-P is algorithm\-2\.




Note that with ANALYZE the cost estimates are
better aligned with reality and algorithm\-1 is
selected by both NN and N3\.



(Side note: The costs estimates in the two most recent graphs
were computed by the NGQP using a base\-2 logarithm and slightly different
cost assumptions compared to the legacy query planner.
Hence, the cost estimates in
these latter two graphs are not directly comparable to the cost estimates
in the TPC\-H Q8 graph.)


