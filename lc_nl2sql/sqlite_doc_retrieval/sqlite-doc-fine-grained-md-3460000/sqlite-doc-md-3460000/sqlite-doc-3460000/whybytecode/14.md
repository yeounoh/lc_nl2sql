## 3\.2\. Dataflow Programs Are Easy To Parallelize


In a dataflow program, each processing node can be assigned to a
different thread. There needs to be some kind of threadsafe queuing
mechanism for transferring intermediate results from one node to the
next. But no synchronization primitives are typically needed within
each node of the program. Node schedule is trivial: A node becomes
eligible to run when it has data available and there is space in its
output queue.



This is an important consideration for database engines that are
designed to run large analytic queries 
([OLAP](https://en.wikipedia.org/wiki/Online_analytical_processing))
on large multi\-core servers.
The primary focus of SQLite is transaction processing 
([OLTP](https://en.wikipedia.org/wiki/Online_transaction_processing)) 
on the internet\-of\-things, so there is less need to
represent prepared statements as dataflow programs in SQLite.


*This page last modified on [2024\-05\-09 17:38:03](https://sqlite.org/docsrc/honeypot) UTC* 


