### Test 1: 1000 INSERTs



> CREATE TABLE t1(a INTEGER, b INTEGER, c VARCHAR(100\));  
> 
> INSERT INTO t1 VALUES(1,13153,'thirteen thousand one hundred fifty three');  
> 
> INSERT INTO t1 VALUES(2,75560,'seventy five thousand five hundred sixty');  
> 
> *... 995 lines omitted*  
> 
> INSERT INTO t1 VALUES(998,66289,'sixty six thousand two hundred eighty nine');  
> 
> INSERT INTO t1 VALUES(999,24322,'twenty four thousand three hundred twenty two');  
> 
> INSERT INTO t1 VALUES(1000,94142,'ninety four thousand one hundred forty two');



| PostgreSQL: | 4\.373 |
| --- | --- |
| MySQL: | 0\.114 |
| SQLite 2\.7\.6: | 13\.061 |
| SQLite 2\.7\.6 (nosync): | 0\.223 |



Because it does not have a central server to coordinate access,
SQLite must close and reopen the database file, and thus invalidate
its cache, for each transaction. In this test, each SQL statement
is a separate transaction so the database file must be opened and closed
and the cache must be flushed 1000 times. In spite of this, the asynchronous
version of SQLite is still nearly as fast as MySQL. Notice how much slower
the synchronous version is, however. SQLite calls **fsync()** after
each synchronous transaction to make sure that all data is safely on
the disk surface before continuing. For most of the 13 seconds in the
synchronous test, SQLite was sitting idle waiting on disk I/O to complete.


