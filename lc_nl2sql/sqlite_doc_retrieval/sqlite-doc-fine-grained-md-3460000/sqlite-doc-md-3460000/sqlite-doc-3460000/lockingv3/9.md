## 6\.0 How To Corrupt Your Database Files


The pager module is very robust but it can be subverted. 
This section attempts to identify and explain the risks.
(See also the [Things That Can Go Wrong](atomiccommit.html#sect_9_0) section of the article
on [Atomic Commit](atomiccommit.html).



Clearly, a hardware or operating system fault that introduces incorrect data
into the middle of the database file or journal will cause problems.
Likewise, 
if a rogue process opens a database file or journal and writes malformed
data into the middle of it, then the database will become corrupt.
There is not much that can be done about these kinds of problems
so they are given no further attention.




SQLite uses POSIX advisory locks to implement locking on Unix. On
Windows it uses the LockFile(), LockFileEx(), and UnlockFile() system
calls. SQLite assumes that these system calls all work as advertised. If
that is not the case, then database corruption can result. One should
note that POSIX advisory locking is known to be buggy or even unimplemented
on many NFS implementations (including recent versions of Mac OS X)
and that there are reports of locking problems
for network filesystems under Windows. Your best defense is to not
use SQLite for files on a network filesystem.




SQLite uses the fsync() system call to flush data to the disk under Unix and
it uses the FlushFileBuffers() to do the same under Windows. Once again,
SQLite assumes that these operating system services function as advertised.
But it has been reported that fsync() and FlushFileBuffers() do not always
work correctly, especially with some network filesystems or inexpensive IDE disks.
Apparently some manufactures of IDE disks have controller chips that report
that data has reached the disk surface when in fact the data is still
in volatile cache memory in the disk drive electronics. There are also
reports that Windows sometimes chooses to ignore FlushFileBuffers() for
unspecified reasons. The author cannot verify any of these reports.
But if they are true, it means that database corruption is a possibility
following an unexpected power loss. These are hardware and/or operating
system bugs that SQLite is unable to defend against.




If a Linux [ext3](http://en.wikipedia.org/wiki/Ext3)
filesystem is mounted without the "barrier\=1" option
in the [/etc/fstab](http://en.wikipedia.org/wiki/fstab)
and the disk drive write cache is enabled
then filesystem corruption can occur following a power loss or OS crash.
Whether or not corruption can occur depends on the details of the disk control
hardware; corruption is more likely with inexpensive consumer\-grade disks
and less of a problem for enterprise\-class storage devices with advanced
features such as non\-volatile write caches.
Various ext3 experts
[confirm this behavior](http://www.redhat.com/archives/ext3-users/2010-July/msg00001.html).
We are told that most Linux distributions do not use barrier\=1 and do
not disable the write cache so most
Linux distributions are vulnerable to this problem. Note that this is an
operating system and hardware issue and that there is nothing that SQLite
can do to work around it. 
[Other database engines](http://ozlabs.org/~rusty/index.cgi/tech/2009-10-20.html) have also run into this same problem.



If a crash or power failure occurs and results in a hot journal but that
journal is deleted, the next process to open the database will not
know that it contains changes that need to be rolled back. The rollback
will not occur and the database will be left in an inconsistent state.
Rollback journals might be deleted for any number of reasons:



* An administrator might be cleaning up after an OS crash or power failure,
 see the journal file, think it is junk, and delete it.
* Someone (or some process) might rename the database file but fail to
 also rename its associated journal.
* If the database file has aliases (hard or soft links) and the file
 is opened by a different alias than the one used to create the journal,
 then the journal will not be found. To avoid this problem, you should
 not create links to SQLite database files.
* Filesystem corruption following a power failure might cause the
 journal to be renamed or deleted.



The last (fourth) bullet above merits additional comment. When SQLite creates
a journal file on Unix, it opens the directory that contains that file and
calls fsync() on the directory, in an effort to push the directory information
to disk. But suppose some other process is adding or removing unrelated
files to the directory that contains the database and journal at the
moment of a power failure. The supposedly unrelated actions of this other
process might result in the journal file being dropped from the directory and
moved into "lost\+found". This is an unlikely scenario, but it could happen.
The best defenses are to use a journaling filesystem or to keep the
database and journal in a directory by themselves.




For a commit involving multiple databases and a super\-journal, if the
various databases were on different disk volumes and a power failure occurs
during the commit, then when the machine comes back up the disks might
be remounted with different names. Or some disks might not be mounted
at all. When this happens the individual file journals and the
super\-journal might not be able to find each other. The worst outcome from
this scenario is that the commit ceases to be atomic. 
Some databases might be rolled back and others might not. 
All databases will continue to be self\-consistent.
To defend against this problem, keep all databases
on the same disk volume and/or remount disks using exactly the same names
after a power failure.




